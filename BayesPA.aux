\relax 
\bibstyle{plainnat}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{crammer2006pa}
\citation{McDonald2005parsing,chiang2008emnlp}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{hjort2010bayesian,teh2006hierarchical}
\citation{hjort2010bayesian}
\citation{Griffiths:tr05}
\citation{hoffman2013stochastic,mimno2012sparse}
\citation{welling2011bayesian,welling2012mc}
\citation{broderick2013streaming}
\citation{jaakkola1999maximum}
\citation{Zhu:jmlr09}
\citation{zhu2012medlda}
\citation{xu2013fast}
\citation{jebara2011mtl,zhu2011infinite}
\citation{zhu2013bayesian}
\citation{zhugibbs2013}
\citation{zhu2013scalable}
\citation{zhu2012medlda}
\citation{teh2006hierarchical}
\citation{hannan1957approximation}
\citation{rosenblatt1958perceptron}
\citation{littlestone1988learning}
\citation{freund1997decision}
\citation{arora2012multiplicative}
\citation{crammer2006pa}
\citation{dredze2008confidence}
\citation{pereira2008exact}
\citation{murphy2012machine_reget}
\citation{shalev2006convex}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}}
\newlabel{sec:relatedwork}{{2}{3}{\relax }{section.2}{}}
\citation{hoffman2013stochastic}
\citation{hoffman2013stochastic}
\citation{mimno2012sparse}
\citation{wang2011onlinealgo,wang2012truncation}
\citation{doucet2009tutorial}
\citation{doucet2000rao}
\citation{canini2009online}
\citation{steinhardt2014filtering}
\citation{korattikara2014austerity}
\citation{bardenet2014towards}
\citation{welling2011bayesian,welling2012mc,patterson2013stochastic}
\citation{broderick2013streaming}
\citation{Vapnik:95}
\citation{koller2003max}
\citation{jaakkola1999maximum,jebara2001discriminative,Zhu:jmlr09}
\citation{zhu2012medlda}
\citation{zhu2011infinite}
\citation{zhu2011infinite}
\citation{zhu2012maxlink}
\citation{Xu:NIPS12}
\citation{zhu2013bayesian}
\citation{zhu2012medlda}
\citation{jiang2012monte}
\citation{zhugibbs2013}
\citation{chen2013generalized}
\citation{xu2013fast}
\citation{dempster1977maximum}
\citation{tanner1987calculation}
\citation{swendsen1987nonuniversal}
\citation{van2001art}
\citation{shi2014bayespa}
\citation{crammer2006pa}
\citation{crammer2006pa}
\@writefile{toc}{\contentsline {section}{\numberline {3}Preliminaries}{5}{section.3}}
\newlabel{sec:pre}{{3}{5}{\relax }{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Online Passive-Aggressive Learning}{5}{subsection.3.1}}
\newlabel{sec:pa}{{3.1}{5}{Online Passive-Aggressive Learning\relax }{subsection.3.1}{}}
\newlabel{eq:pa}{{1}{5}{Online Passive-Aggressive Learning\relax }{equation.3.1}{}}
\citation{crammer2006pa}
\citation{broderick2013streaming}
\citation{broderick2013streaming}
\citation{wainwright2008graphical}
\citation{minka2001expectation}
\citation{hoffman2013stochastic}
\citation{honkela2003line,luts2013real}
\citation{broderick2013streaming}
\citation{zhu2013bayesian}
\newlabel{eq:pa-soft}{{2}{6}{Online Passive-Aggressive Learning\relax }{equation.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Streaming Variational Bayes}{6}{subsection.3.2}}
\newlabel{eq:stream-Bayes-update}{{3}{6}{Streaming Variational Bayes\relax }{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Regularized Bayesian Inference}{6}{subsection.3.3}}
\citation{durret2010}
\citation{zhu2013bayesian}
\citation{zhu2013bayesian}
\citation{jiang2012monte,zhugibbs2013}
\citation{Xu:NIPS12,xu2013fast}
\citation{zhu2012maxlink}
\newlabel{eq:regBayes}{{4}{7}{Regularized Bayesian Inference\relax }{equation.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Bayesian Passive-Aggressive Learning}{7}{section.4}}
\newlabel{sec:bpal}{{4}{7}{Regularized Bayesian Inference\relax }{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Online BayesPA Learning}{7}{subsection.4.1}}
\newlabel{eq:onlinepa}{{5}{7}{Online BayesPA Learning\relax }{equation.4.5}{}}
\citation{cortes1995support}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Graphical Illustration of BayesPA learning. \textbf  {(a)}. Update \emph  {passively} by Bayes rule, if the resulting distribution suffer zero loss. \textbf  {(b)} Otherwise, \emph  {aggressively} project the resulting distribution to the feasible zone of weights with zero loss. }}{8}{figure.1}}
\newlabel{fig:bayesPA}{{1}{8}{Graphical Illustration of BayesPA learning. \textbf {(a)}. Update \emph {passively} by Bayes rule, if the resulting distribution suffer zero loss. \textbf {(b)} Otherwise, \emph {aggressively} project the resulting distribution to the feasible zone of weights with zero loss}{figure.1}{}}
\newlabel{eq:onlinepa_reg}{{6}{8}{Online BayesPA Learning\relax }{equation.4.6}{}}
\citation{zhu2012medlda}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The comparison between BayesPA and its various precursors, including online PA, streaming variational Bayes (SVB) and regularized Bayesian inference (RegBayes), in three different aspects.}}{9}{table.1}}
\newlabel{table:relationship}{{1}{9}{The comparison between BayesPA and its various precursors, including online PA, streaming variational Bayes (SVB) and regularized Bayesian inference (RegBayes), in three different aspects}{table.1}{}}
\newlabel{lm:loss}{{1}{9}{Online BayesPA Learning\relax }{theorem.4.1}{}}
\newlabel{tm:subsume}{{2}{9}{Online BayesPA Learning\relax }{theorem.4.2}{}}
\newlabel{eq:onlinepa_reg_app}{{7}{9}{Online BayesPA Learning\relax }{equation.4.7}{}}
\newlabel{eq:optimal}{{8}{9}{Online BayesPA Learning\relax }{equation.4.8}{}}
\newlabel{eq:dual}{{9}{9}{Online BayesPA Learning\relax }{equation.4.9}{}}
\citation{crammer2006pa}
\newlabel{eq:dualx}{{10}{10}{Online BayesPA Learning\relax }{equation.4.10}{}}
\newlabel{lemma:avgBayesPA-Rep}{{3}{10}{Online BayesPA Learning\relax }{theorem.4.3}{}}
\newlabel{eq:avgBayesPA-optimal}{{11}{10}{Online BayesPA Learning\relax }{equation.4.11}{}}
\newlabel{lm:pagibbs}{{4}{10}{Online BayesPA Learning\relax }{theorem.4.4}{}}
\newlabel{eq:onlinepa_gibbs}{{12}{10}{Online BayesPA Learning\relax }{equation.4.12}{}}
\citation{crammer2006pa}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Graphical illustrations of: (a) the abstraction of models with latent structures; and (b) the procedure of BayesPA learning with latent structures.}}{11}{figure.2}}
\newlabel{fig:LatentBayesPA}{{2}{11}{Graphical illustrations of: (a) the abstraction of models with latent structures; and (b) the procedure of BayesPA learning with latent structures}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}BayesPA Learning with Latent Structures}{11}{subsection.4.2}}
\newlabel{sec:pa_latent}{{4.2}{11}{BayesPA Learning with Latent Structures\relax }{subsection.4.2}{}}
\citation{zhu2012medlda}
\citation{murphy2012machine_reget,shalev2006convex}
\newlabel{eq:bayespa_latent}{{13}{12}{BayesPA Learning with Latent Structures\relax }{equation.4.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Theoretical Analysis}{12}{section.5}}
\newlabel{sec:theory}{{5}{12}{BayesPA Learning with Latent Structures\relax }{section.5}{}}
\newlabel{tm:gibbs-new}{{6}{12}{A regret bound for BayesPA with Gibbs classifiers\relax }{theorem.5.6}{}}
\newlabel{eq:gibbsnlpa_bound-new}{{15}{12}{A regret bound for BayesPA with Gibbs classifiers\relax }{equation.5.15}{}}
\citation{bayes-bounds}
\newlabel{tm:avg}{{8}{13}{A regret bound for BayesPA with averaging classifiers\relax }{theorem.5.8}{}}
\newlabel{eq:avgnlpa_bound}{{16}{13}{A regret bound for BayesPA with averaging classifiers\relax }{equation.5.16}{}}
\citation{adams2007bayesian}
\citation{blei2003lda}
\citation{blei2010supervised,zhu2012medlda}
\citation{jiang2012monte}
\@writefile{toc}{\contentsline {section}{\numberline {6}Online Max-Margin Topic Models}{14}{section.6}}
\newlabel{sec:pamedlda}{{6}{14}{BayesPA Learning with Latent Structures\relax }{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Basics of MedLDA}{14}{subsection.6.1}}
\citation{zhugibbs2013}
\citation{chang2010hierarchical}
\citation{griffiths2004finding,teh2006collapsed}
\citation{jordan1998introduction}
\newlabel{eq:disc-func-latent}{{17}{15}{Basics of MedLDA\relax }{equation.6.17}{}}
\newlabel{eq:batch_bayes_loss}{{18}{15}{Basics of MedLDA\relax }{equation.6.18}{}}
\newlabel{eq:batch_gibbs_loss}{{19}{15}{Basics of MedLDA\relax }{equation.6.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Online MedLDA}{15}{subsection.6.2}}
\newlabel{sec:medlda}{{6.2}{15}{Online MedLDA\relax }{subsection.6.2}{}}
\newlabel{eq:medlda-avg-bayes}{{20}{15}{Online MedLDA\relax }{equation.6.20}{}}
\citation{zhu2012medlda}
\newlabel{eq:optimal_phi_ave}{{21}{16}{Online MedLDA\relax }{equation.6.21}{}}
\newlabel{eq:lda_phi2}{{22}{16}{Online MedLDA\relax }{equation.6.22}{}}
\newlabel{eq:optimal_qw_ave}{{23}{16}{Online MedLDA\relax }{equation.6.23}{}}
\newlabel{eq:pa_avgupdate_w}{{24}{16}{Online MedLDA\relax }{equation.6.24}{}}
\newlabel{eq:pamedlda_dual}{{25}{16}{Online MedLDA\relax }{equation.6.25}{}}
\citation{shalev2011pegasos}
\citation{zhu2012medlda}
\newlabel{eq:pamedlda_primal}{{26}{17}{Online MedLDA\relax }{equation.6.26}{}}
\newlabel{eq_bayespaave_gradient}{{27}{17}{Online MedLDA\relax }{equation.6.27}{}}
\citation{zhugibbs2013}
\citation{zhugibbs2013}
\citation{tanner1987calculation,polson2011data}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {Online MedLDA}}}{18}{algorithm.1}}
\newlabel{algo:pamMedLDAave}{{1}{18}{Online MedLDA\relax }{algorithm.1}{}}
\newlabel{eq:lda_sample_z_ave}{{28}{18}{Online MedLDA\relax }{equation.6.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Online Gibbs MedLDA}{18}{subsection.6.3}}
\newlabel{sec:gibbsmedlda}{{6.3}{18}{Online Gibbs MedLDA\relax }{subsection.6.3}{}}
\citation{zhugibbs2013}
\citation{jordan1998introduction}
\newlabel{eq:scalemix}{{29}{19}{Online Gibbs MedLDA\relax }{equation.6.29}{}}
\newlabel{eq:online-solution-augmented}{{30}{19}{Online Gibbs MedLDA\relax }{}{}}
\newlabel{eq:onlinepa_augmented}{{30}{19}{Online Gibbs MedLDA\relax }{equation.6.30}{}}
\newlabel{eq:lda_weight}{{31}{19}{Online Gibbs MedLDA\relax }{equation.6.31}{}}
\newlabel{eq:lda_weight2}{{31}{19}{Online Gibbs MedLDA\relax }{equation.6.31}{}}
\citation{mimno2012sparse}
\citation{devroye1986sample}
\citation{Michael:IG76}
\citation{teh2006hierarchical}
\newlabel{eq:pamedlda_zlambda}{{32}{20}{Online Gibbs MedLDA\relax }{equation.6.32}{}}
\newlabel{eq:lda_sample_z}{{32}{20}{Online Gibbs MedLDA\relax }{equation.6.32}{}}
\newlabel{eq:lda_sample_lambda}{{33}{20}{Online Gibbs MedLDA\relax }{equation.6.33}{}}
\citation{wang2012truncation}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \parsep 4.5\p@ plus2\p@ minus\p@ \topsep 9\p@ plus3\p@ minus5\p@ \itemsep 4.5\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {Online Gibbs MedLDA}}}{21}{algorithm.2}}
\newlabel{algo:pamedlda}{{2}{21}{Online Gibbs MedLDA\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Extensions}{21}{section.7}}
\newlabel{sec:extensions}{{7}{21}{Online Gibbs MedLDA\relax }{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Online Nonparametric MedLDA}{21}{subsection.7.1}}
\newlabel{sec:ohdp}{{7.1}{21}{Online Nonparametric MedLDA\relax }{subsection.7.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Batch MedHDP}{21}{subsubsection.7.1.1}}
\newlabel{sec:medhdp}{{7.1.1}{21}{Batch MedHDP\relax }{subsubsection.7.1.1}{}}
\newlabel{eq:medhdp}{{34}{21}{Batch MedHDP\relax }{equation.7.34}{}}
\citation{teh2006hierarchical,wang2012split}
\citation{zhugibbs2013}
\citation{welling2008hybrid,wang2012truncation}
\citation{teh2006hierarchical,wang2012truncation}
\citation{antoniak1974mixtures}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Online MedHDP}{22}{subsubsection.7.1.2}}
\newlabel{eq:joint_zs}{{35}{22}{Online MedHDP\relax }{equation.7.35}{}}
\newlabel{eq:onlinemedhdp_augmented}{{36}{22}{Online MedHDP\relax }{equation.7.36}{}}
\newlabel{eq:hdp_beta}{{37}{22}{Online MedHDP\relax }{equation.7.37}{}}
\citation{wang2012truncation}
\newlabel{eq:pamedhdp_zlambdas}{{39}{23}{Online MedHDP\relax }{equation.7.39}{}}
\newlabel{eq:hdp_approx}{{40}{23}{Online MedHDP\relax }{equation.7.40}{}}
\newlabel{eq:hdp_approx_augmented}{{41}{23}{Online MedHDP\relax }{equation.7.41}{}}
\newlabel{eq:hdp_sample_z_ave}{{43}{23}{Online MedHDP\relax }{equation.7.43}{}}
\newlabel{eq:hdp_sample_z2}{{2}{23}{Online MedHDP\relax }{equation.7.43}{}}
\newlabel{eq:hdp_sample_s}{{44}{24}{Online MedHDP\relax }{equation.7.44}{}}
\newlabel{eq:hdp_sample_pi}{{45}{24}{Online MedHDP\relax }{equation.7.45}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Online Gibbs MedHDP}{24}{subsubsection.7.1.3}}
\newlabel{eq:pamedhdp_zlambdas2}{{46}{24}{Online Gibbs MedHDP\relax }{equation.7.46}{}}
\newlabel{eq:hdp_sample_z_gibbs}{{47}{24}{Online Gibbs MedHDP\relax }{equation.7.47}{}}
\citation{zhu2012medlda}
\citation{rifkin2004defense}
\citation{zhu2012medlda}
\citation{zhugibbs2013}
\citation{jiang2012monte}
\citation{mimno2012sparse}
\citation{hoffman2013stochastic}
\citation{chang2011libsvm}
\citation{zhu2012medlda}
\citation{blei2010supervised}
\citation{lacoste2008disclda}
\citation{zhugibbs2013}
\newlabel{eq:hdp_sample_z2}{{2}{25}{Online Gibbs MedHDP\relax }{equation.7.47}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Multi-task Learning}{25}{subsection.7.2}}
\newlabel{sec:mtl}{{7.2}{25}{Multi-task Learning\relax }{subsection.7.2}{}}
\newlabel{eq:onlinepa_latent_mt}{{7.2}{25}{Multi-task Learning\relax }{subsection.7.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Experiments}{25}{section.8}}
\newlabel{sec:exp}{{8}{25}{Multi-task Learning\relax }{section.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Classification on 20Newsgroup}{25}{subsection.8.1}}
\newlabel{sec:mc}{{8.1}{25}{Classification on 20Newsgroup\relax }{subsection.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Test errors of different models with respect to the number of passes through the 20NG training data set. }}{26}{figure.3}}
\newlabel{fg:multic_commit}{{3}{26}{Test errors of different models with respect to the number of passes through the 20NG training data set}{figure.3}{}}
\citation{zhu2012medlda,zhugibbs2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Extensions}{27}{subsection.8.2}}
\citation{wang2012truncation}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Classification accuracy and running time of various models with respect to the number of topics on the 20NG data set.}}{28}{figure.4}}
\newlabel{fg:multic_topic_lda}{{4}{28}{Classification accuracy and running time of various models with respect to the number of topics on the 20NG data set}{figure.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1}Nonparametric Topic Modeling}{28}{subsubsection.8.2.1}}
\citation{zhu2013scalable}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2}Multi-Task Classification}{29}{subsubsection.8.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Sensitivity Analysis}{29}{subsection.8.3}}
\newlabel{sec:sensitivity}{{8.3}{29}{Sensitivity Analysis\relax }{subsection.8.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces F1 scores of various multi-task topic models with respect to the running time on the 1.1M wikipedia data set.}}{30}{figure.5}}
\newlabel{fg:multic_mtask_commit}{{5}{30}{F1 scores of various multi-task topic models with respect to the running time on the 1.1M wikipedia data set}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Test errors of $\text  {paMedLDA}^{\text  {ave}}$~(left) and $\text  {paMedLDA}^{\text  {gibbs}}$~(right) with different batch sizes on the 20NG data set. }}{31}{figure.6}}
\newlabel{fg:multic_batchsize}{{6}{31}{Test errors of \paMedLDAave (left) and \paMedLDAgibbs (right) with different batch sizes on the 20NG data set}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Test errors of $\text  {paMedHDP}^{\text  {ave}}$~(left) and $\text  {paMedHDP}^{\text  {gibbs}}$~(right) with different batch sizes on the 20NG data set. }}{31}{figure.7}}
\newlabel{fg:multic_batchsize_hdp}{{7}{31}{Test errors of \paMedHDPave (left) and \paMedHDPgibbs (right) with different batch sizes on the 20NG data set}{figure.7}{}}
\citation{broderick2013streaming}
\citation{zhu2012maxlink}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Classification accuracies and training time of \textbf  {(a)}: $\text  {paMedLDA}^{\text  {gibbs}}$~, \textbf  {(b):} $\text  {paMedHDP}^{\text  {gibbs}}$~, \textbf  {(c)}: $\text  {paMedLDA}^{\text  {ave}}$~, and \textbf  {(d):} $\text  {paMedHDP}^{\text  {ave}}$~, with different combinations of $(\mathcal  {I}, \mathcal  {J})$ on the 20NG data set. The x-axis includes different values of $\mathcal  {J}$, while different values of $\mathcal  {I}$ are shown as separate lines. }}{32}{figure.8}}
\newlabel{fg:multic_IJ}{{8}{32}{Classification accuracies and training time of \textbf {(a)}: \paMedLDAgibbs , \textbf {(b):} \paMedHDPgibbs , \textbf {(c)}: \paMedLDAave , and \textbf {(d):} \paMedHDPave , with different combinations of $(\mathcal {I}, \mathcal {J})$ on the 20NG data set. The x-axis includes different values of $\mathcal {J}$, while different values of $\mathcal {I}$ are shown as separate lines}{figure.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Conclusions and Future Work}{32}{section.9}}
\newlabel{sec:con}{{9}{32}{Sensitivity Analysis\relax }{section.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}}{33}{appendix.A}}
\newlabel{app:regret-bound}{{A}{33}{Acknowledgements\relax }{appendix.A}{}}
\newlabel{eq:bayespa_dual}{{48}{33}{Acknowledgements\relax }{equation.A.48}{}}
\newlabel{eq:avg_key_bound}{{49}{33}{Acknowledgements\relax }{equation.A.49}{}}
\newlabel{eq:kl_diff}{{50}{33}{Acknowledgements\relax }{equation.A.50}{}}
\bibdata{BayesPA}
\bibcite{adams2007bayesian}{{1}{2007}{{Adams and MacKay}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {B}}{34}{appendix.B}}
\newlabel{app:upperbound}{{B}{34}{Acknowledgements\relax }{appendix.B}{}}
\newlabel{eq:varbound}{{51}{34}{Acknowledgements\relax }{equation.B.51}{}}
\newlabel{eq:boundlemma_entropy}{{52}{34}{Acknowledgements\relax }{equation.B.52}{}}
\newlabel{eq:boundlemma}{{53}{34}{Acknowledgements\relax }{equation.B.53}{}}
\bibcite{welling2012mc}{{2}{2012}{{Ahn et~al.}}{{Ahn, Korattikara, and Welling}}}
\bibcite{antoniak1974mixtures}{{3}{1974}{{Antoniak}}{{}}}
\bibcite{arora2012multiplicative}{{4}{2012}{{Arora et~al.}}{{Arora, Hazan, and Kale}}}
\bibcite{bayes-bounds}{{5}{2006}{{Banerjee}}{{}}}
\bibcite{bardenet2014towards}{{6}{2014}{{Bardenet et~al.}}{{Bardenet, Doucet, and Holmes}}}
\bibcite{blei2010supervised}{{7}{2010}{{Blei and McAuliffe}}{{}}}
\bibcite{blei2003lda}{{8}{2003}{{Blei et~al.}}{{Blei, Ng, and Jordan}}}
\bibcite{broderick2013streaming}{{9}{2013}{{Broderick et~al.}}{{Broderick, Boyd, Wibisono, Wilson, and Jordan}}}
\bibcite{canini2009online}{{10}{2009}{{Canini et~al.}}{{Canini, Shi, and Griffiths}}}
\bibcite{chang2011libsvm}{{11}{2011}{{Chang and Lin}}{{}}}
\bibcite{chang2010hierarchical}{{12}{2010}{{Chang and Blei}}{{}}}
\bibcite{chen2013generalized}{{13}{2013}{{Chen et~al.}}{{Chen, Zhu, Xia, and Zhang}}}
\bibcite{chiang2008emnlp}{{14}{2008}{{Chiang et~al.}}{{Chiang, Marton, and Resnik}}}
\bibcite{cortes1995support}{{15}{1995}{{Cortes and Vapnik}}{{}}}
\bibcite{crammer2006pa}{{16}{2006}{{Crammer et~al.}}{{Crammer, Dekel, Keshet, Shalel-Shwartz, and Singer}}}
\bibcite{pereira2008exact}{{17}{2008}{{Crammer et~al.}}{{Crammer, Dredze, and Pereira}}}
\bibcite{dempster1977maximum}{{18}{1977}{{Dempster et~al.}}{{Dempster, Laird, and Rubin}}}
\bibcite{devroye1986sample}{{19}{1986}{{Devroye}}{{}}}
\bibcite{doucet2009tutorial}{{20}{2009}{{Doucet and Johansen}}{{}}}
\bibcite{doucet2000rao}{{21}{2000}{{Doucet et~al.}}{{Doucet, De~Freitas, Murphy, and Russell}}}
\bibcite{dredze2008confidence}{{22}{2008}{{Dredze et~al.}}{{Dredze, Crammer, and Pereira}}}
\bibcite{durret2010}{{23}{2010}{{Durret}}{{}}}
\bibcite{freund1997decision}{{24}{1997}{{Freund and Schapire}}{{}}}
\bibcite{Griffiths:tr05}{{25}{2005}{{Ghahramani and Griffiths}}{{}}}
\bibcite{griffiths2004finding}{{26}{2004}{{Griffiths and Steyvers}}{{}}}
\bibcite{hannan1957approximation}{{27}{1957}{{Hannan}}{{}}}
\bibcite{hjort2010bayesian}{{28}{2010}{{Hjort}}{{}}}
\bibcite{hoffman2013stochastic}{{29}{2013}{{Hoffman et~al.}}{{Hoffman, Blei, Wang, and Paisley}}}
\bibcite{honkela2003line}{{30}{2003}{{Honkela and Valpola}}{{}}}
\bibcite{jaakkola1999maximum}{{31}{1999}{{Jaakkola et~al.}}{{Jaakkola, Meila, and Jebara}}}
\bibcite{jebara2001discriminative}{{32}{2001}{{Jebara}}{{}}}
\bibcite{jebara2011mtl}{{33}{2011}{{Jebara}}{{}}}
\bibcite{jiang2012monte}{{34}{2012}{{Jiang et~al.}}{{Jiang, Zhu, Sun, and Xing}}}
\bibcite{jordan1998introduction}{{35}{1998}{{Jordan et~al.}}{{Jordan, Ghahramani, Jaakkola, and Saul}}}
\bibcite{korattikara2014austerity}{{36}{2014}{{Korattikara et~al.}}{{Korattikara, Chen, and Welling}}}
\bibcite{lacoste2008disclda}{{37}{2008}{{Lacoste-Julien et~al.}}{{Lacoste-Julien, Sha, and Jordan}}}
\bibcite{littlestone1988learning}{{38}{1988}{{Littlestone}}{{}}}
\bibcite{luts2013real}{{39}{2013}{{Luts et~al.}}{{Luts, Broderick, and Wand}}}
\bibcite{McDonald2005parsing}{{40}{2005}{{McDonald et~al.}}{{McDonald, Crammer, and Pereira}}}
\bibcite{Michael:IG76}{{41}{1976}{{Michael et~al.}}{{Michael, Schucany, and Haas}}}
\bibcite{mimno2012sparse}{{42}{2012}{{Mimno et~al.}}{{Mimno, Hoffman, and Blei}}}
\bibcite{minka2001expectation}{{43}{2001}{{Minka}}{{}}}
\bibcite{murphy2012machine_reget}{{44}{2012}{{Murphy}}{{}}}
\bibcite{patterson2013stochastic}{{45}{2013}{{Patterson and Teh}}{{}}}
\bibcite{polson2011data}{{46}{2011}{{Polson and Scott}}{{}}}
\bibcite{rifkin2004defense}{{47}{2004}{{Rifkin and Klautau}}{{}}}
\bibcite{rosenblatt1958perceptron}{{48}{1958}{{Rosenblatt}}{{}}}
\bibcite{shalev2006convex}{{49}{2006}{{Shalev-Shwartz and Singer}}{{}}}
\bibcite{shalev2011pegasos}{{50}{2011}{{Shalev-Shwartz et~al.}}{{Shalev-Shwartz, Singer, Srebro, and Cotter}}}
\bibcite{shi2014bayespa}{{51}{2014}{{Shi and Zhu}}{{}}}
\bibcite{steinhardt2014filtering}{{52}{2014}{{Steinhardt and Liang}}{{}}}
\bibcite{swendsen1987nonuniversal}{{53}{1987}{{Swendsen and Wang}}{{}}}
\bibcite{tanner1987calculation}{{54}{1987}{{Tanner and Wong}}{{}}}
\bibcite{koller2003max}{{55}{2003}{{Taskar et~al.}}{{Taskar, Guestrin, and Koller}}}
\bibcite{teh2006hierarchical}{{56}{2006{a}}{{Teh et~al.}}{{Teh, Jordan, Beal, and Blei}}}
\bibcite{teh2006collapsed}{{57}{2006{b}}{{Teh et~al.}}{{Teh, Newman, and Welling}}}
\bibcite{van2001art}{{58}{2001}{{Van~Dyk and Meng}}{{}}}
\bibcite{Vapnik:95}{{59}{1995}{{Vapnik}}{{}}}
\bibcite{wainwright2008graphical}{{60}{2008}{{Wainwright and Jordan}}{{}}}
\bibcite{wang2012split}{{61}{2012{a}}{{Wang and Blei}}{{}}}
\bibcite{wang2012truncation}{{62}{2012{b}}{{Wang and Blei}}{{}}}
\bibcite{wang2011onlinealgo}{{63}{2011}{{Wang et~al.}}{{Wang, Paisley, and Blei}}}
\bibcite{welling2011bayesian}{{64}{2011}{{Welling and Teh}}{{}}}
\bibcite{welling2008hybrid}{{65}{2008}{{Welling et~al.}}{{Welling, Teh, and Kappen}}}
\bibcite{Xu:NIPS12}{{66}{2012}{{Xu et~al.}}{{Xu, Zhu, and Zhang}}}
\bibcite{xu2013fast}{{67}{2013}{{Xu et~al.}}{{Xu, Zhu, and Zhang}}}
\bibcite{zhu2012maxlink}{{68}{2012}{{Zhu}}{{}}}
\bibcite{Zhu:jmlr09}{{69}{2009}{{Zhu and Xing}}{{}}}
\bibcite{zhu2011infinite}{{70}{2011}{{Zhu et~al.}}{{Zhu, Chen, and Xing}}}
\bibcite{zhu2012medlda}{{71}{2012}{{Zhu et~al.}}{{Zhu, Ahmed, and Xing}}}
\bibcite{zhu2013scalable}{{72}{2013}{{Zhu et~al.}}{{Zhu, Zheng, Zhou, and Zhang}}}
\bibcite{zhugibbs2013}{{73}{2014{a}}{{Zhu et~al.}}{{Zhu, Chen, Perkins, and Zhang}}}
\bibcite{zhu2013bayesian}{{74}{2014{b}}{{Zhu et~al.}}{{Zhu, Chen, and Xing}}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Visualization of the learnt topics by $\text  {paMedLDA}^{\text  {ave}}$~and $\text  {paMedLDA}^{\text  {gibbs}}$~. See text for details.{\color  {red}{\bf  \sf  pdf files need cut off boundary.}}}}{40}{table.2}}
\newlabel{tb:visualization_gibbs}{{2}{40}{Visualization of the learnt topics by \paMedLDAave and \paMedLDAgibbs . See text for details.\junx {pdf files need cut off boundary.}\relax }{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Effect of the number of local samples and burn-in steps for \textbf  {(a).} $\text  {paMedLDA}^{\text  {ave}}$~; and \textbf  {(b).} $\text  {paMedLDA}^{\text  {gibbs}}$~.}}{41}{table.3}}
\newlabel{tb:samplen}{{3}{41}{Effect of the number of local samples and burn-in steps for \textbf {(a).} \paMedLDAave ; and \textbf {(b).} \paMedLDAgibbs }{table.3}{}}
